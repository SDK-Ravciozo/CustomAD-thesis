{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94894ce",
   "metadata": {},
   "source": [
    "## 1. CSVs created:\n",
    "\n",
    "- ./CSV/dataset_info.csv\n",
    "\n",
    "        For each split of the dataset, lists the exact train and test sizes, as well as the anomaly train and test sizes\n",
    "\n",
    "- ./CSV/test_on_splits.csv\n",
    "\n",
    "        For each split, get the runtime, AUC and other results for running MIDAS with LP (not custom)\n",
    "\n",
    "\n",
    "## 2. Some code to prove the superiority/correctness of our approaches:\n",
    "\n",
    "- Splitting works\n",
    "\n",
    "- sum(y) is faster than y.count(1)\n",
    "\n",
    "- .intersection() or .union() are faster than nx.jaccard_coefficient\n",
    "\n",
    "## 3. Some \"edge ranking\" stuff from Yao's code that seems highly unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "warming-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "from Midas import FilteringCore, NormalCore, RelationalCore\n",
    "from random import uniform, randint\n",
    "\n",
    "from thesis_library import *\n",
    "from Custom_sketch import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2204c656",
   "metadata": {},
   "source": [
    "### Create dataset info has simply this single line to invoke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76861d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_dataset_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52abbe6",
   "metadata": {},
   "source": [
    "### Create rav_test_on_splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4751f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grand_test(midas_list: list, datasets: list, lp_methods: list, df=None) -> None:\n",
    "    '''\n",
    "    1) Runs a given MIDAS (or none) on the ENTIRE dataset\n",
    "    2) Saves the pure MIDAS score on the entire dataset\n",
    "    3) Splits the scores alongside the data to update them with LP scores\n",
    "    4) Updates the scores for each split size and tests all LP methods and None\n",
    "    \n",
    "    If no dataframe is passed, a new one is created and saved at ./CSV/rav_test_on_splits.csv'''\n",
    "    \n",
    "    #TO DO: fix that:\n",
    "    print(\"Trying a total of\", 9*len(midas_list)*len(datasets)*(len(lp_methods)+1), \"combinations.\")\n",
    "    \n",
    "    if df is None and 'test_on_splits.csv' not in os.listdir('./CSV'):\n",
    "        df = pd.DataFrame(columns=['Split (train:test)', 'Dataset', '#nodes', '#edges', 'MIDAS', \n",
    "                                   'Method', 'AUC', 'Runtime'])\n",
    "    \n",
    "    #Handling the dataset loop:\n",
    "    for dataset in datasets:\n",
    "        print(\"Reading dataset\", dataset)\n",
    "        X, y = read_data(dataset, plant='clique')\n",
    "        \n",
    "        #Handling the MIDAS loop:\n",
    "        for midas_name in midas_list:\n",
    "            if midas_name in ['normal', 'Normal', 'MIDAS']:\n",
    "                midas, midas_name = NormalCore(2, 1024), 'MIDAS'       #2048 buckets\n",
    "            elif midas_name in ['relational', 'Relational', 'MIDAS-R']:\n",
    "                midas, midas_name = RelationalCore(2, 1024), 'MIDAS-R' #2048 buckets\n",
    "            elif midas_name in ['custom', 'Custom']:\n",
    "                midas, midas_name = MIDAS(3, 48, 3), 'Custom'          #432 buckets #1728 buckets\n",
    "            elif midas_name in [None, 'None', 'none', 'No sketch']:\n",
    "                midas, midas_name = None, \"No sketch\"\n",
    "            else:\n",
    "                raise ValueError(\"MIDAS version not supported. Pass 'normal', 'relational', 'none'.\")\n",
    "\n",
    "            #Running MIDAS on the entire dataset - the scores will be split\n",
    "            if midas_name in ['MIDAS', 'MIDAS-R']:\n",
    "                score = [0.0] * len(y)\n",
    "                t1 = time.time()\n",
    "                for i in trange(len(y), desc=midas.nameAlg, unit_scale=True):\n",
    "                    score[i] = midas.Call(*X[i])\n",
    "                t2 = time.time()\n",
    "                time_taken = round(t2-t1, 4)\n",
    "                auc = roc_auc_score(y, score)\n",
    "            elif midas_name in ['Custom']:\n",
    "                auc, time_taken, score = midas.process_dataset(dataset, return_score=True, verbose=False)\n",
    "            else:\n",
    "                score, auc, time_taken = [1.0] * len(y), -1, 0\n",
    "            \n",
    "            #Saving the MIDAS score anyway:\n",
    "            df.loc[df.shape[0]] = [\"00:10\", dataset, -1, -1, midas_name, 'No LP', auc, time_taken]\n",
    "            df.to_csv('./CSV/test_on_splits.csv', index=False)\n",
    "            \n",
    "            #Avoid using no sketch + No LP combo:\n",
    "            if midas_name != 'No sketch':\n",
    "                lp_methods += ['No LP']\n",
    "\n",
    "            for test_size in [round(1 - 0.1*(i+1), 2) for i in range(8, 9)]: #TO DO CHANGE TO 0, 9\n",
    "\n",
    "                print(\"Processing\", get_split_name(test_size))\n",
    "\n",
    "                #Preparing the split:\n",
    "                X_train, X_test, y_train, y_test, score_test = split(X, y, test_size, score)\n",
    "                G = construct_training_graph(X_train, y_train, True, False) #Not saving anomalies in\n",
    "\n",
    "                #Looping over the 3 available LP methods + the None LP method:\n",
    "                for method in lp_methods: \n",
    "\n",
    "                    #print(\"Trying MIDAS version \" + midas_name + \" and LP method:\" + method)\n",
    "                    t1 = time.time()\n",
    "                    method_score = apply_lp(method, score_test, X_test, G)\n",
    "                    auc = roc_auc_score(y_test, method_score) if sum(y_test) !=0 else -1\n",
    "                    t2 = time.time()\n",
    "\n",
    "                    df.loc[df.shape[0]] = [get_split_name(test_size), dataset, G.number_of_nodes(), G.number_of_edges(), \n",
    "                                           midas_name, method, auc, round(t2-t1, 4)]\n",
    "\n",
    "                    time.sleep(20)\n",
    "\n",
    "                df.to_csv('./CSV/test_on_splits.csv', index=False)\n",
    "\n",
    "                time.sleep(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8a2544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying a total of 18 combinations.\n",
      "Reading dataset CTU13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rav_sketch: 100%|████████████████████████████████████████████████████████████████| 2.52M/2.52M [01:49<00:00, 23.1kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|█████████████████████████████████████████████████████████████| 252k/252k [16:12<00:00, 259it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./CSV/test_on_splits.csv')\n",
    "\n",
    "#grand_test(['No sketch', 'MIDAS', 'MIDAS-R', 'Custom'], ['Gowalla'], LP_METHODS, df=df)\n",
    "grand_test(['Custom'], ['CTU13'], ['Common Neighbours'], df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d7ac6c",
   "metadata": {},
   "source": [
    "# Improvement kind-of calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75492932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_midas = pd.read_csv('./CSV/test_on_splits.csv')\n",
    "df_midas = df_midas[(df_midas['MIDAS'] == 'MIDAS') | (df_midas['MIDAS'] == 'MIDAS-R')]\n",
    "df_midas = df_midas[(df_midas['Dataset'] != 'ISCX') & (df_midas['#nodes'] == -1)].reset_index(drop=True)\n",
    "df_midas = df_midas.sort_values('MIDAS')\n",
    "\n",
    "df_advice = pd.read_csv('./CSV/rav_grand_test.csv')\n",
    "df_advice = df_advice[(df_advice['Dataset'] != 'ISCX') & (df_advice['K'] == 8)]\n",
    "df_advice = df_advice[df_advice['Split (train:test)'] == '01:09'].reset_index(drop=True)\n",
    "\n",
    "df_midas['AUC_Custom'] = list(df_advice['AUC_sketch']) * 2\n",
    "df_midas['AUC_Advice'] = list(df_advice['AUC_advice']) * 2\n",
    "df_midas = df_midas[['Dataset', 'MIDAS', 'AUC', 'AUC_Custom', 'AUC_Advice']]\n",
    "\n",
    "df_midas['AUC_MIDAS'] = df_midas[df_midas['MIDAS'] == 'MIDAS']['AUC']\n",
    "df_midas['AUC_MIDAS_R'] = df_midas[df_midas['MIDAS'] == 'MIDAS-R']['AUC']\n",
    "df_midas = df_midas.drop(['MIDAS', 'AUC'], axis=1).reset_index(drop=True)\n",
    "df_midas['AUC_MIDAS_R'][:5] = df_midas['AUC_MIDAS_R'][5:]\n",
    "df_midas = df_midas[:5]\n",
    "df_midas = df_midas[['Dataset', 'AUC_MIDAS', 'AUC_MIDAS_R', 'AUC_Custom', 'AUC_Advice']]\n",
    "\n",
    "df_midas['Advice_over_midas'] = (df_midas['AUC_Advice'] - df_midas['AUC_MIDAS'])/df_midas['AUC_MIDAS'] * 100\n",
    "df_midas['Advice_over_midas_r'] = (df_midas['AUC_Advice'] - df_midas['AUC_MIDAS_R'])/df_midas['AUC_MIDAS_R'] * 100\n",
    "\n",
    "print((df_midas['Advice_over_midas'].mean() + df_midas['Advice_over_midas_r'].mean())/2)\n",
    "df_midas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e121e1c",
   "metadata": {},
   "source": [
    "## Runtime proofs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e599a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirmation the new splitting works\n",
    "\n",
    "X, y = read_data('ISCX')\n",
    "for test_size in [round(1 - 0.1*(i+1), 2) for i in range(0, 9)]:\n",
    "    X_train, X_test, y_train, y_test = split(X, y, test_size)\n",
    "    print(\"Test size:\", test_size)\n",
    "    print(\"X_train size:\", len(X_train))\n",
    "    print(\"X_test size:\", len(X_test))\n",
    "    print(X_train[-1], X_test[0])\n",
    "    print(len(X_test)/len(X))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20eb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_nx_cn, time_pythonic_cn = [], []\n",
    "time_nx_jc, time_pythonic_jc = [], []\n",
    "time_nx_pa, time_pythonic_pa = [], []\n",
    "\n",
    "for nr_iters in [10000, 50000, 100000, 500000, 1000000]:\n",
    "    \n",
    "    print(\"trying currently nr_iters:\", nr_iters)\n",
    "     G = nx.erdos_renyi_graph(250, 0.03)\n",
    "    \n",
    "    # COMMON NEIGHBOURS:\n",
    "    #Pythonic:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = len(set(G[1]).intersection(set(G[25])))\n",
    "    t2 = time.time()\n",
    "    time_pythonic_cn.append(t2 - t1)\n",
    "    \n",
    "    #Networkx:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = len(tuple(nx.common_neighbors(G, 1, 25)))\n",
    "    t2 = time.time()\n",
    "    time_nx_cn.append(t2 - t1)\n",
    "    \n",
    "    # JACCARD COEFFICIENT:\n",
    "    #Pythonic:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = len(set(G[1]).intersection(set(G[25]))) / len(set(G[1]).union(set(G[25])))\n",
    "    t2 = time.time()\n",
    "    time_pythonic_jc.append(t2 - t1)\n",
    "    \n",
    "    #Networkx:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = next(nx.jaccard_coefficient(G, [(1, 25)]))[2]\n",
    "    t2 = time.time()\n",
    "    time_nx_jc.append(t2 - t1)\n",
    "    \n",
    "    #PREFERENTIAL ATTACHMENT:\n",
    "    # Pythonic:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = len(G[1]) * len(G[25])\n",
    "    t2 = time.time()\n",
    "    time_pythonic_pa.append(t2 - t1)\n",
    "    \n",
    "    # Networkx:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = tuple(nx.preferential_attachment(G, [(1, 25)]))[0][2]\n",
    "    t2 = time.time()\n",
    "    time_nx_pa.append(t2 - t1)\n",
    "    \n",
    "#### RESULTS ####\n",
    "df_time = pd.DataFrame({'size': [10000, 50000, 100000, 500000, 1000000], \n",
    "                        'time_nx': time_nx, 'time_pythonic': time_pythonic})\n",
    "df_time['method'] = ['Jaccard coefficient']*5 + ['Common neighbors']*5 + ['Preferential attachment']*5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
