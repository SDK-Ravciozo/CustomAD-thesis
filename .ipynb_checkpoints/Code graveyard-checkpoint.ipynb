{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94894ce",
   "metadata": {},
   "source": [
    "# Finished notebook\n",
    "#### What do we learn from it?\n",
    "## 1. Functions:\n",
    "\n",
    "1) test_split_size_effect:\n",
    "\n",
    "        Splits the dataset, creates training graph, runs the LP methods on the test set\n",
    "\n",
    "        Creates ./CSV/auc_prediction_rav.csv in the process\n",
    "\n",
    "2) test_on_non_splits:\n",
    "\n",
    "        First, runs MIDAS on the entire dataset. Then, splits the dataset and updates the test sores with LP\n",
    "\n",
    "        Creates ./CSV/rav_auc_split.csv\n",
    "\n",
    "3) create_auc_clique_n:\n",
    "\n",
    "        Splits the data, constructs training graphs, imputes a clique into the test set only\n",
    "\n",
    "        Runs MIDAS and MIDAS+LP on the test set\n",
    "\n",
    "        Creates ./CSV/rav_auc_clique_'+str(n)+'.csv, where n is the number of nodes taking part in the clique\n",
    "\n",
    "\n",
    "## 2. CSVs created:\n",
    "\n",
    "- ./CSV/auc_prediction_rav.csv\n",
    "\n",
    "- ./CSV/rav_auc_split.csv\n",
    "\n",
    "- ./CSV/rav_dataset_info.csv\n",
    "\n",
    "        For each split of the dataset, lists the exact train and test sizes, as well as the anomaly train and test sizes\n",
    "\n",
    "- rav_auc_clique_50.csv, where 50 is the number of imputed anomaly edges (clique)\n",
    "\n",
    "\n",
    "## 3. Some code to prove the superiority/correctness of our approaches:\n",
    "\n",
    "- Splitting works\n",
    "\n",
    "- sum(y) is faster than y.count(1)\n",
    "\n",
    "- .intersection() or .union() are faster than nx.jaccard_coefficient\n",
    "\n",
    "## 4. Some \"edge ranking\" stuff that seems highly unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510601a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2edcc494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m[16, 7]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(f\"{bcolors.FAIL}[16, 7]{bcolors.ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a36563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Jupyter core packages...\n",
      "IPython          : 8.12.0\n",
      "ipykernel        : 6.19.2\n",
      "ipywidgets       : 8.1.2\n",
      "jupyter_client   : 8.1.0\n",
      "jupyter_core     : 5.3.0\n",
      "jupyter_server   : 1.23.4\n",
      "jupyterlab       : not installed\n",
      "nbclient         : 0.5.13\n",
      "nbconvert        : 6.5.4\n",
      "nbformat         : 5.7.0\n",
      "notebook         : 6.5.4\n",
      "qtconsole        : not installed\n",
      "traitlets        : 5.7.1\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "warming-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "from tqdm import tqdm, trange\n",
    "from Midas import FilteringCore, NormalCore, RelationalCore\n",
    "from random import uniform, randint\n",
    "\n",
    "from thesis_library import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c62fe661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DARPA 25525\n",
      "NB15 50\n",
      "CTU13 371076\n",
      "Gowalla 1659\n",
      "NYC_Taxi 264\n"
     ]
    }
   ],
   "source": [
    "# #Printing the |V| for all datasets\n",
    "# for dataset in DATASETS:\n",
    "#     X, y = read_data(dataset, plant='clique')\n",
    "#     print(dataset, len(np.union1d(np.unique(np.array(X)[:,0]), np.unique(np.array(X)[:,1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40924be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['counts 1', 'counts 2'])\n",
    "df['counts 1'] = [10, 5, 17, 14, 11, 4, 5, 9, 13, 12] + [7]\n",
    "df['counts 2'] = [0, 0, 23, 14, 2, 1, 37, 2, 3, 18] + [20]\n",
    "\n",
    "# df = pd.DataFrame(columns=['counts raspberry', 'counts blue'])\n",
    "# df['counts raspberry'] = [0, 0, 14, 2, 2] + [20]\n",
    "# df['counts blue'] = [23, 1, 37, 3, 18] + [20]\n",
    "colours_list = ['#B00B55', '#B00B55', '#2E53DC', '#B00B55', '#B00B55', '#2E53DC', '#2E53DC', \\\n",
    "                '#B00B55', '#2E53DC', '#2E53DC'] + ['#38DC2E']\n",
    "\n",
    "plt.figure();\n",
    "ax1 = df['counts 2'].plot(kind='bar', color = ['#B00B55']*10 + ['#38DC2E'], legend=False)\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Edge count');\n",
    "\n",
    "# # these are matplotlib.patch.Patch properties\n",
    "# props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "# ax1.text(0.05, 0.95, \"Mean = 10\", transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props)\n",
    "\n",
    "# plt.figure();\n",
    "# ax2 = df['counts 2'].plot(kind='bar', color = ['#365D33']*10 + ['#533955'], legend=False)\n",
    "# plt.xlabel('Timestamp')\n",
    "# plt.ylabel('Edge count');\n",
    "# ax2.text(0.05, 0.95, \"Mean = 10\", transform=ax.transAxes, fontsize=14, verticalalignment='top', bbox=props);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ac114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_methods(dataset: str, test_size: float, threshold=10) -> tuple:\n",
    "#     '''\n",
    "#     Returns a triple of the AUC scores of the following methods:\n",
    "#     Common Neighbours, Jaccard Coefficient, Preferential Attachment\n",
    "    \n",
    "#     If the case imbalance in the test set is too extreme (threshold param), returns None, None, None instead\n",
    "#     '''\n",
    "    \n",
    "#     print(\"Reading data\")\n",
    "#     data, label = read_data(dataset = dataset, plant='clique')\n",
    "    \n",
    "#     print(\"Splitting data\")\n",
    "#     X_train, X_test, y_train, y_test = split(data, label, test_size=test_size)\n",
    "    \n",
    "#     print(\"Constructing the training graph (anomalies disallowed)\")\n",
    "#     G = construct_training_graph(X_train, y_train, True, False)\n",
    "    \n",
    "#     print(\"Filtering the test set\")\n",
    "#     X_test, y_test = filter_test(X_test, y_test, G)\n",
    "    \n",
    "#     #AUC / ROC is ill-defined with an extreme case imbalance\n",
    "#     if sum(y_test) > threshold: #sum(y_test) is the number of anomalous edges\n",
    "        \n",
    "#         print(\"Invoking the Link Prediction methods \\n\")\n",
    "#         print(\"Dataset length:   \", len(y_test))\n",
    "#         print(\"Anomalies present:\", sum(y_test))\n",
    "        \n",
    "#         cn = apply_lp('Common Neighbours', [1]*len(y_test), X_test, G)\n",
    "#         jc = apply_lp('Jaccard Coefficient', [1]*len(y_test), X_test, G)\n",
    "#         pa = apply_lp('Preferential Attachment', [1]*len(y_test), X_test, G)\n",
    "        \n",
    "#         cn, jc, pa = roc_auc_score(y_test, cn), roc_auc_score(y_test, jc), roc_auc_score(y_test, pa)\n",
    "        \n",
    "#         cn, jc, pa = round(cn, 4), round(jc, 4), round(pa, 4)\n",
    "        \n",
    "#         return cn, jc, pa, len(y_test), sum(y_test)\n",
    "        \n",
    "#     else:\n",
    "#         print(\"Not enough anomalous edges in the test set, only\", sum(y_test))\n",
    "#         return -1, -1, -1, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83127ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cn_auc, jc_auc, pa_auc, _, _ = evaluate_methods(dataset=\"ISCX\", test_size=0.1)\n",
    "\n",
    "# print('')\n",
    "# print(\"Common Neighbours AUC:      \", cn_auc)\n",
    "# print(\"Jaccard Coefficient AUC:    \", jc_auc)\n",
    "# print(\"Preferential Attachment AUC:\", pa_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_split_size_effect(df = None) -> None:\n",
    "#     '''\n",
    "#     Runs the evaluate_methods code for all 1:9 up to 9:1 train-test-split settings\n",
    "#     Saves the results to a dataframe called \"auc_prediction_rav.csv\"\n",
    "#     If the dataframe has already been created, pass it as an argument to append to it\n",
    "#     Otherwise, the results may be overwritten!\n",
    "#     '''\n",
    "    \n",
    "#     if df is None:\n",
    "#         df = pd.DataFrame({\"Split (train:test)\": [], \"Dataset\": [], \"Test size (overall)\": [], \\\n",
    "#                            \"Test size (anomaly)\": [], \"Method\": [], \"AUC\": []})\n",
    "        \n",
    "#     for dataset in DATASETS:\n",
    "#         for test_size in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "            \n",
    "#             print(dataset, test_size)\n",
    "            \n",
    "#             #Just for display purposes:\n",
    "#             split_name = get_split_name(test_size)\n",
    "            \n",
    "#             #Getting the AUCs:\n",
    "#             cn_auc, jc_auc, pa_auc, n, n_anomaly = evaluate_methods(dataset=dataset, test_size=test_size)\n",
    "            \n",
    "#             #Saving the results into the resul dataframe:\n",
    "#             df.loc[df.shape[0]] = [split_name, dataset, n, n_anomaly, \"Common neighbours\", cn_auc]\n",
    "#             df.loc[df.shape[0]] = [split_name, dataset, n, n_anomaly, \"Jaccard coefficient\", jc_auc]\n",
    "#             df.loc[df.shape[0]] = [split_name, dataset, n, n_anomaly, \"Preferential attachment\", pa_auc]\n",
    "            \n",
    "#             #Saving the intermediate results and cooling down the processor:\n",
    "#             df.to_csv(\"./CSV/auc_prediction_rav.csv\", index=False)\n",
    "#             time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93990e",
   "metadata": {},
   "source": [
    "### The pipeline of the above for a different test_size split (runs 3 hours):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a3da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"./CSV/auc_prediction_rav.csv\")\n",
    "# test_split_size_effect(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b1afbb",
   "metadata": {},
   "source": [
    "### Obtaining the score data for pure Preferential Attachment for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e566fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2204c656",
   "metadata": {},
   "source": [
    "### Create dataset info has simply this single line to invoke:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76861d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_dataset_info(DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d29c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def impute_clique(X_test, y_test, n: int) -> tuple:\n",
    "#     '''Perhaps it would be wiser to allow new nodes here?\n",
    "#     Imputing a clique of 0 nodes equals to not doing anything at all! Use it!'''\n",
    "    \n",
    "#     final_t = X_test[-1][-1]+1\n",
    "#     for i in range(n): #is starting from 0 okay?\n",
    "#         for j in range(n):\n",
    "#             if i != j:\n",
    "#                 X_test.append([i, j, final_t])\n",
    "#                 y_test.append(1)\n",
    "            \n",
    "#     return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77653846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_auc_clique_n(n: int, midas_list: list, datasets: list, lp_methods: list, df_clique=None):\n",
    "#     '''\n",
    "#     1) Splits the data\n",
    "#     2) Constructs training graph on the train split\n",
    "#     3) Imputes an n-clique into the test data (pass n=0 for no imputation)\n",
    "#     4) Runs MIDAS score on the test set\n",
    "#     5) Updates it with Link Prediction scores\n",
    "#     '''\n",
    "    \n",
    "#     assert midas_version in [\"normal\", 'relational'], \"Use 'normal' or 'relational'\"\n",
    "    \n",
    "#     if df_clique is None:\n",
    "#         df_clique = pd.DataFrame(columns=[\"Split (train:test)\", \"Dataset\", \"Midas_version\", \"Method\", \"AUC\", 'Time'])\n",
    "    \n",
    "#     print(\"Trying a total of\", 9*len(midas_list)*len(datasets)*(len(lp_methods)+1), \" combinations.\")\n",
    "    \n",
    "#     ####### MAIN LOOP ###########\n",
    "#     for dataset in datasets:\n",
    "#         print(\"Reading dataset:\", dataset)\n",
    "#         X, y = read_data(dataset)\n",
    "        \n",
    "#         #Handling the proper MIDAS version and its display name:\n",
    "#         for midas_name in midas_list:\n",
    "#             if midas_name == 'normal':\n",
    "#                 midas, midas_name = NormalCore(2, 1024), 'MIDAS'\n",
    "#             elif midas_name == \"relational\":\n",
    "#                 midas, midas_name = RelationalCore(2, 1024), 'MIDAS-R'\n",
    "#             else:\n",
    "#                 raise ValueError(\"MIDAS version not supported. Pass 'normal' or 'relational'.\")\n",
    "            \n",
    "#             #Handling the proper train-test split size:\n",
    "#             for test_size in [round(0.1*(i+1), 2) for i in range(0, 9)]:\n",
    "\n",
    "#                 #Splitting the data:\n",
    "#                 X_train, X_test, y_train, y_test = split(X, y, test_size)\n",
    "\n",
    "#                 G = construct_training_graph(X_train, y_train)\n",
    "\n",
    "#                 X_test, y_test = impute_clique(X_test, y_test, n) #not too fast of an implementation\n",
    "\n",
    "#                 #Setting up a proper midas version and its display name for the CSV filename:\n",
    "#                 if midas_version == 'normal':\n",
    "#                     midas, midas_version = NormalCore(2, 1024), \"MIDAS\"\n",
    "#                 elif midas_version == 'relational':\n",
    "#                     midas, midas_version = RelationalCore(2, 1024), \"MIDAS-R\"\n",
    "\n",
    "#                 #Obtaining the results for pure MIDAS:\n",
    "#                 score = [0.0] * len(y_test)\n",
    "#                 t1 = time.time()\n",
    "\n",
    "#                 for i in trange(len(y_test), desc=midas.nameAlg, unit_scale=True):\n",
    "#                     score[i] = midas.Call(*X_test[i])\n",
    "#                     #score[i] = midas.process_edge(*X_test[i])\n",
    "\n",
    "#                 t2 = time.time()\n",
    "#                 auc = roc_auc_score(y_test, score)\n",
    "\n",
    "#                 df_clique.loc[df_clique.shape[0]] = [get_split_name(test_size), dataset, midas_version, \\\n",
    "#                                                      'none', auc, round(t2-t1, 4)]\n",
    "\n",
    "#                 #Reinforcing the scores with LP methods:\n",
    "#                 for method in lp_methods:\n",
    "#                     t1 = time.time()\n",
    "#                     method_score = apply_lp(method, score, X_test, G)\n",
    "#                     auc = roc_auc_score(y_test, method_score)\n",
    "#                     t2 = time.time()\n",
    "#                     df_clique.loc[df_clique.shape[0]] = [get_split_name(test_size), dataset, midas_version, \\\n",
    "#                                                          method, auc, round(t2-t1, 4)]\n",
    "\n",
    "#                 #Saving all the results:\n",
    "#                 df_clique.to_csv('./CSV/rav_auc_clique_'+str(n)+'.csv', index=False)\n",
    "#                 time.sleep(15)\n",
    "\n",
    "#             time.sleep(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df1332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./CSV/rav_auc_clique_30.csv')\n",
    "# create_acc_clique_n(0, ['normal', 'relational'], DATASETS, LP_METHODS, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee2b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_on_non_splits(midas_list: list, datasets: list, lp_methods: list, df=None) -> None:\n",
    "#     '''First, runs a given MIDAS on the ENTIRE dataset\n",
    "#     Then, splits the scores alongside the data to update them with LP scores\n",
    "#     If no dataframe is passed, a new one is created and saved at ./CSV/rav_auc_split.csv'''\n",
    "    \n",
    "#     print(\"Trying a total of\", 9*len(midas_list)*len(datasets)*(len(lp_methods)+1), \"combinations.\")\n",
    "    \n",
    "#     if df is None:\n",
    "#         df = pd.DataFrame(columns=['Split (train:test)', 'Dataset', '#nodes', '#edges', 'MIDAS', \n",
    "#                                    'Method', 'AUC', 'Time [s]'])\n",
    "    \n",
    "#     #Handling the dataset loop:\n",
    "#     for dataset in datasets:\n",
    "#         print(\"Reading dataset\", dataset)\n",
    "#         X, y = read_data(dataset)\n",
    "        \n",
    "#         #Handling the MIDAS loop:\n",
    "#         for midas_name in midas_list:\n",
    "#             if midas_name == 'normal':\n",
    "#                 midas, midas_name = NormalCore(2, 1024), 'MIDAS'\n",
    "#             elif midas_name == \"relational\":\n",
    "#                 midas, midas_name = RelationalCore(2, 1024), 'MIDAS-R'\n",
    "#             elif midas_name == 'custom':\n",
    "#                 print(\"Setting up the custom MIDAS.\")\n",
    "#                 midas, midas_name = MIDAS(4, 5, 3, is_switchboard=False), \"Custom\"\n",
    "#             else:\n",
    "#                 raise ValueError(\"MIDAS version not supported. Pass 'normal', 'relational', 'custom'.\")\n",
    "            \n",
    "#             #Running MIDAS on the entire dataset - the scores will be split\n",
    "#             score = [0.0] * len(y)\n",
    "#             for i in trange(len(y), desc=midas.nameAlg, unit_scale=True):\n",
    "#                 score[i] = midas.Call(*X[i])\n",
    "#                 #score[i] = midas.process_edge(*X[i])\n",
    "#             auc = roc_auc_score(y, score)\n",
    "            \n",
    "#             #Saving the MIDAS score anyway:\n",
    "#             df.loc[df.shape[0]] = [\"10:00\", dataset, -1, -1, midas_name, 'none', auc, -1]\n",
    "#             df.to_csv('./CSV/rav_auc_split.csv', index=False)\n",
    "            \n",
    "#             for test_size in [round(0.1*(i+1), 2) for i in range(0, 9)]:\n",
    "                \n",
    "#                 print(\"Processing\", get_split_name(test_size))\n",
    "                \n",
    "#                 #Preparing the split:\n",
    "#                 X_train, X_test, y_train, y_test, score_test = split(X, y, test_size, score)\n",
    "#                 G = construct_training_graph(X_train, y_train, True, False) #Not saving anomalies in\n",
    "                \n",
    "#                 #Looping over the 3 available LP methods:\n",
    "#                 for method in lp_methods: \n",
    "                    \n",
    "#                     start_time = time.time()\n",
    "#                     method_score = apply_lp(method, score_test, X_test, G)\n",
    "#                     auc = roc_auc_score(y_test, method_score) if sum(y_test) !=0 else -1\n",
    "#                     end_time = time.time()\n",
    "                    \n",
    "#                     df.loc[df.shape[0]] = [get_split_name(test_size), dataset, G.number_of_nodes(), G.number_of_edges(), \n",
    "#                                            midas_name, method, auc, round(end_time-start_time, 4)]\n",
    "                    \n",
    "#                     time.sleep(20)\n",
    "                    \n",
    "#                 df.to_csv('./CSV/rav_auc_split.csv', index=False)\n",
    "                \n",
    "#                 time.sleep(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1249334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./CSV/rav_auc_split.csv')\n",
    "# test_on_non_splits(midas_list = ['normal', 'relational'], datasets = ['NYC_Taxi'], lp_methods=LP_METHODS, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4751f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grand_test(midas_list: list, datasets: list, lp_methods: list, df=None) -> None:\n",
    "    '''First, runs a given MIDAS on the ENTIRE dataset\n",
    "    Then, splits the scores alongside the data to update them with LP scores\n",
    "    If no dataframe is passed, a new one is created and saved at ./CSV/rav_test_on_splits.csv'''\n",
    "    \n",
    "    print(\"Trying a total of\", 9*len(midas_list)*len(datasets)*(len(lp_methods)+1), \"combinations.\")\n",
    "    \n",
    "    if df is None:\n",
    "        df = pd.DataFrame(columns=['Split (train:test)', 'Dataset', '#nodes', '#edges', 'MIDAS', \n",
    "                                   'Method', 'AUC', 'Runtime'])\n",
    "    \n",
    "    #Handling the dataset loop:\n",
    "    for dataset in datasets:\n",
    "        print(\"Reading dataset\", dataset)\n",
    "        X, y = read_data(dataset, plant='clique')\n",
    "        \n",
    "        #Handling the MIDAS loop:\n",
    "        for midas_name in midas_list:\n",
    "            if midas_name in ['normal', 'Normal', 'MIDAS']:\n",
    "                midas, midas_name = NormalCore(2, 1024), 'MIDAS'\n",
    "            elif midas_name in ['relational', 'Relational', 'MIDAS-R']:\n",
    "                midas, midas_name = RelationalCore(2, 1024), 'MIDAS-R'\n",
    "            elif midas_name in [None, 'None', 'none']:\n",
    "                midas, midas_name = None, \"None\"\n",
    "            else:\n",
    "                raise ValueError(\"MIDAS version not supported. Pass 'normal', 'relational', 'none'.\")\n",
    "            \n",
    "            #Running MIDAS on the entire dataset - the scores will be split\n",
    "            if midas_name not in [None, 'None', 'none']:\n",
    "                score = [0.0] * len(y)\n",
    "                t1 = time.time()\n",
    "                for i in trange(len(y), desc=midas.nameAlg, unit_scale=True):\n",
    "                    score[i] = midas.Call(*X[i])\n",
    "                t2 = time.time()\n",
    "                time_taken = round(t2-t1, 4)\n",
    "                auc = roc_auc_score(y, score)\n",
    "            else:\n",
    "                score, auc, time_taken = [1.0] * len(y), -1, 0\n",
    "            \n",
    "            #Saving the MIDAS score anyway:\n",
    "            df.loc[df.shape[0]] = [\"10:00\", dataset, -1, -1, midas_name, 'None', auc, time_taken]\n",
    "            df.to_csv('./CSV/rav_test_on_splits.csv', index=False)\n",
    "            \n",
    "            for test_size in [round(0.1*(i+1), 2) for i in range(0, 9)]:\n",
    "                \n",
    "                print(\"Processing\", get_split_name(test_size))\n",
    "                \n",
    "                #Preparing the split:\n",
    "                X_train, X_test, y_train, y_test, score_test = split(X, y, test_size, score)\n",
    "                G = construct_training_graph(X_train, y_train, True, False) #Not saving anomalies in\n",
    "                \n",
    "                #Looping over the 3 available LP methods + the None LP method:\n",
    "                for method in lp_methods+['None']: \n",
    "                    \n",
    "                    t1 = time.time()\n",
    "                    method_score = apply_lp(method, score_test, X_test, G)\n",
    "                    auc = roc_auc_score(y_test, method_score) if sum(y_test) !=0 else -1\n",
    "                    t2 = time.time()\n",
    "                    \n",
    "                    df.loc[df.shape[0]] = [get_split_name(test_size), dataset, G.number_of_nodes(), G.number_of_edges(), \n",
    "                                           midas_name, method, auc, round(t2-t1, 4)]\n",
    "                    \n",
    "                    time.sleep(20)\n",
    "                    \n",
    "                df.to_csv('./CSV/rav_test_on_splits.csv', index=False)\n",
    "                \n",
    "                time.sleep(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "207bf3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gowalla', 'NYC_Taxi']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8a2544b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying a total of 135 combinations.\n",
      "Reading dataset DARPA\n",
      "Processing 9:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|███████████████████████████████████████████████████████████| 455k/455k [00:12<00:00, 37.4kit/s]\n",
      "Preferential Attachment: 100%|██████████████████████████████████████████████████████| 455k/455k [00:00<00:00, 456kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|███████████████████████████████████████████████████████████| 909k/909k [00:26<00:00, 34.0kit/s]\n",
      "Preferential Attachment: 100%|██████████████████████████████████████████████████████| 909k/909k [00:01<00:00, 468kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 7:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|█████████████████████████████████████████████████████████| 1.37M/1.37M [00:37<00:00, 36.8kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 1.37M/1.37M [00:02<00:00, 512kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|█████████████████████████████████████████████████████████| 1.82M/1.82M [00:47<00:00, 38.0kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 1.82M/1.82M [00:03<00:00, 505kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|█████████████████████████████████████████████████████████| 2.28M/2.28M [00:50<00:00, 45.1kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 2.28M/2.28M [00:04<00:00, 513kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|█████████████████████████████████████████████████████████| 2.73M/2.73M [00:47<00:00, 57.6kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 2.73M/2.73M [00:03<00:00, 711kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|█████████████████████████████████████████████████████████| 3.19M/3.19M [00:36<00:00, 87.4kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 3.19M/3.19M [00:04<00:00, 731kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|██████████████████████████████████████████████████████████| 3.64M/3.64M [00:33<00:00, 109kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 3.64M/3.64M [00:05<00:00, 622kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|██████████████████████████████████████████████████████████| 4.09M/4.09M [00:22<00:00, 179kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 4.09M/4.09M [00:07<00:00, 534kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset NB15\n",
      "Processing 9:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|████████████████████████████████████████████████████████████| 254k/254k [00:00<00:00, 306kit/s]\n",
      "Preferential Attachment: 100%|██████████████████████████████████████████████████████| 254k/254k [00:00<00:00, 518kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|████████████████████████████████████████████████████████████| 508k/508k [00:01<00:00, 332kit/s]\n",
      "Preferential Attachment: 100%|██████████████████████████████████████████████████████| 508k/508k [00:00<00:00, 547kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 7:3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|████████████████████████████████████████████████████████████| 762k/762k [00:02<00:00, 322kit/s]\n",
      "Preferential Attachment: 100%|██████████████████████████████████████████████████████| 762k/762k [00:01<00:00, 493kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6:4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|██████████████████████████████████████████████████████████| 1.02M/1.02M [00:02<00:00, 348kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 1.02M/1.02M [00:02<00:00, 484kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 5:5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|██████████████████████████████████████████████████████████| 1.27M/1.27M [00:03<00:00, 326kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 1.27M/1.27M [00:02<00:00, 506kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|██████████████████████████████████████████████████████████| 1.52M/1.52M [00:03<00:00, 386kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 1.52M/1.52M [00:02<00:00, 605kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 3:7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|██████████████████████████████████████████████████████████| 1.78M/1.78M [00:04<00:00, 365kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 1.78M/1.78M [00:02<00:00, 594kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2:8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|██████████████████████████████████████████████████████████| 2.03M/2.03M [00:05<00:00, 382kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 2.03M/2.03M [00:03<00:00, 622kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1:9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours: 100%|██████████████████████████████████████████████████████████| 2.29M/2.29M [00:06<00:00, 329kit/s]\n",
      "Preferential Attachment: 100%|████████████████████████████████████████████████████| 2.29M/2.29M [00:04<00:00, 520kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset CTU13\n",
      "Processing 9:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Common Neighbours:  73%|████████████████████████████████████████████▋                | 185k/252k [11:32<04:12, 267it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m lp_methods \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCommon Neighbours\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPreferential Attachment\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./CSV/rav_test_on_splits.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m grand_test([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m], DATASETS[\u001b[38;5;241m1\u001b[39m:], lp_methods, df\u001b[38;5;241m=\u001b[39mdf)\n",
      "Cell \u001b[1;32mIn[12], line 56\u001b[0m, in \u001b[0;36mgrand_test\u001b[1;34m(midas_list, datasets, lp_methods, df)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m lp_methods\u001b[38;5;241m+\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m]: \n\u001b[0;32m     55\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 56\u001b[0m     method_score \u001b[38;5;241m=\u001b[39m apply_lp(method, score_test, X_test, G)\n\u001b[0;32m     57\u001b[0m     auc \u001b[38;5;241m=\u001b[39m roc_auc_score(y_test, method_score) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(y_test) \u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     58\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32m~\\Desktop\\TUe\\Master Thesis\\thesis_library.py:263\u001b[0m, in \u001b[0;36mapply_lp\u001b[1;34m(method, score, X_test, G)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;28mlen\u001b[39m(X_test), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(method), unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    262\u001b[0m         u, v \u001b[38;5;241m=\u001b[39m X_test[i][\u001b[38;5;241m0\u001b[39m], X_test[i][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 263\u001b[0m         cn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(G[u])\u001b[38;5;241m.\u001b[39mintersection(\u001b[38;5;28mset\u001b[39m(G[v]))) \u001b[38;5;28;01mif\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m G \u001b[38;5;129;01mand\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m G \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    264\u001b[0m         method_score[i] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mcn)\u001b[38;5;241m*\u001b[39mscore[i] \u001b[38;5;28;01mif\u001b[39;00m cn\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m score[i]\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJaccard coefficient\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJaccard Coefficient\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJC\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lp_methods = ['Common Neighbours', 'Preferential Attachment']\n",
    "df = pd.read_csv('./CSV/rav_test_on_splits.csv')\n",
    "grand_test(['None'], DATASETS[4:], lp_methods, df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e121e1c",
   "metadata": {},
   "source": [
    "## Runtime proofs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e599a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirmation the new splitting works\n",
    "\n",
    "# X, y = read_data('ISCX')\n",
    "# for test_size in [round(0.1*(i+1), 2) for i in range(0, 9)]:\n",
    "#     X_train, X_test, y_train, y_test = split(X, y, test_size)\n",
    "#     print(X_train[-1])\n",
    "#     print(X_test[0])\n",
    "#     print(len(X_test)/(len(X_train)+len(X_test)))\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20eb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_nx_cn, time_pythonic_cn = [], []\n",
    "time_nx_jc, time_pythonic_jc = [], []\n",
    "time_nx_pa, time_pythonic_pa = [], []\n",
    "\n",
    "for nr_iters in [10000, 50000, 100000, 500000, 1000000]:\n",
    "    \n",
    "    print(\"trying currently nr_iters:\", nr_iters)\n",
    "     G = nx.erdos_renyi_graph(250, 0.03)\n",
    "    \n",
    "    # COMMON NEIGHBOURS:\n",
    "    #Pythonic:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = len(set(G[1]).intersection(set(G[25])))\n",
    "    t2 = time.time()\n",
    "    time_pythonic_cn.append(t2 - t1)\n",
    "    \n",
    "    #Networkx:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = len(tuple(nx.common_neighbors(G, 1, 25)))\n",
    "    t2 = time.time()\n",
    "    time_nx_cn.append(t2 - t1)\n",
    "    \n",
    "    # JACCARD COEFFICIENT:\n",
    "    #Pythonic:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = len(set(G[1]).intersection(set(G[25]))) / len(set(G[1]).union(set(G[25])))\n",
    "    t2 = time.time()\n",
    "    time_pythonic_jc.append(t2 - t1)\n",
    "    \n",
    "    #Networkx:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = next(nx.jaccard_coefficient(G, [(1, 25)]))[2]\n",
    "    t2 = time.time()\n",
    "    time_nx_jc.append(t2 - t1)\n",
    "    \n",
    "    #PREFERENTIAL ATTACHMENT:\n",
    "    # Pythonic:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = len(G[1]) * len(G[25])\n",
    "    t2 = time.time()\n",
    "    time_pythonic_pa.append(t2 - t1)\n",
    "    \n",
    "    # Networkx:\n",
    "    t1 = time.time()\n",
    "    for _ in range(nr_iters):\n",
    "        wow = tuple(nx.preferential_attachment(G, [(1, 25)]))[0][2]\n",
    "    t2 = time.time()\n",
    "    time_nx_pa.append(t2 - t1)\n",
    "    \n",
    "#### RESULTS ####\n",
    "df_time = pd.DataFrame({'size': [10000, 50000, 100000, 500000, 1000000], \n",
    "                        'time_nx': time_nx, 'time_pythonic': time_pythonic})\n",
    "df_time['method'] = ['Jaccard coefficient']*5 + ['Common neighbors']*5 + ['Preferential attachment']*5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee01c39",
   "metadata": {},
   "source": [
    "## Some fuckery about edge ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict new edges\n",
    "\n",
    "# 1. split dataset\n",
    "# 2. make a graph for training dataset\n",
    "#    - ignore the anomaly edges\n",
    "# 3. process test dataset\n",
    "#    - delete anomaly edges?\n",
    "#    - delete edges already in train dataset\n",
    "#    - delete edges wihich nodes are not in train dataset\n",
    "# 3. for every two nodes in training dataset, compute cn,jc,pa\n",
    "#    - ignore edges already in train dataset\n",
    "#    - output a ranked list\n",
    "# 4. take the first n pairs from ranked list, determine the size of the intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c6b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_edges_ranking(dataset: str):\n",
    "    '''This code is more-or-less useless due to insane running time\n",
    "    Returns a sorted dataframe of all possible edges and their scores\n",
    "    This might be a massive dataset, so proceed with caution\n",
    "    Does not filter out testing/training edges from the final dataframe\n",
    "    \n",
    "    Converting an iterator into a tuple works (For me) at almost 1M elements per second'''\n",
    "    \n",
    "    data, label = read_data(dataset=dataset)\n",
    "    \n",
    "    train, test, train_label, test_label = split(data, label, test_size = 0.5)\n",
    "\n",
    "    G = construct_training_graph(train, train_label)\n",
    "\n",
    "#     X_test, y_test = filter_test(test, test_label, G)\n",
    "\n",
    "#     #Filtering out the anomalies from the test dataset\n",
    "#     good_rows = [(edge[0], edge[1], label) for (edge, label) in zip(X_test, y_test) if label==0]\n",
    "#     X_test, y_test = [(edge[0], edge[1]) for edge in good_rows], [edge[2] for edge in good_rows]\n",
    "\n",
    "    df = pd.DataFrame(columns=['u', 'v', 'CommonNeighbours','JaccardCoefficient','PreferentialAttachment'])\n",
    "    print(\"Total number of possible edges:\", len(list(combinations(G.nodes,2))))\n",
    "    \n",
    "    #Getting the iterator objects of Jaccard and PrefAtt scores for all pairs of nodes in the G object\n",
    "    jacc = nx.jaccard_coefficient(G)\n",
    "    pref = nx.preferential_attachment(G)\n",
    "    \n",
    "    #Converting these massive generators into tuples might take massive amount of time:\n",
    "    df['JaccardCoefficient'] = tuple(jacc)\n",
    "    df['PreferentialAttachment'] = tuple(pref)\n",
    "    \n",
    "    #And calling the CommonNeighbours on every single pair of nodes might also be super time-consuming:\n",
    "    df['CommonNeighbours'] = df['JaccardCoefficient'].apply(lambda x: len(tuple(nx.common_neighbors(G, x[0], x[1]))))\n",
    "    \n",
    "    #Lastly, retrieve the integer labels of the nodes (might as well be a large computation)\n",
    "    df['u'] = df['JaccardCoefficient'].apply(lambda x: x[0])\n",
    "    df['v'] = df['JaccardCoefficient'].apply(lambda x: x[1])\n",
    "    \n",
    "    df.sort_values(by = ['CommonNeighbours', 'JaccardCoefficient', 'PreferentialAttachment'], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976a2f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0205024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dafc064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_dataset_plot(dataset: str, show_train=True, show_test=True):\n",
    "    '''TO DO: decide whether this is even needed. \n",
    "    IMO it is not, for AUC_on_splits (plot_auc_and_split_per_dataset) does that too, but better'''\n",
    "    \n",
    "    #Using only the proper part of the dataset\n",
    "    df, dataset_info = split_data_reader(dataset)\n",
    "    \n",
    "    reference_values = df[df['Method'] == 'No LP'].reset_index(drop=True)\n",
    "    reference_values = reference_values['AUC'][0], reference_values['AUC'][1]\n",
    "    \n",
    "    plt.figure(figsize=(8,8), dpi=100)\n",
    "    \n",
    "    #The AUC plot:\n",
    "    ax1 = plt.subplot(311)\n",
    "    sns.pointplot(x = 'Split (train:test)', y = 'AUC', hue = 'Method', data = df, ax=ax1)\n",
    "    \n",
    "    ax1.axhline(y = reference_values[0], linestyle = '--') #MIDAS\n",
    "    ax1.axhline(y = reference_values[1], linestyle = '--') #MIDAS-R\n",
    "    \n",
    "    plt.title('ROC/AUC in dataset ' + dataset)\n",
    "    plt.xticks([])\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('AUC/ROC')\n",
    "    \n",
    "    #The anomaly % plot for training data:\n",
    "    if show_train:\n",
    "        ax2 = plt.subplot(312)\n",
    "        sns.pointplot(x = 'Split (train:test)', y = 'Train_anomaly_percentage', \n",
    "                      hue = 'Dataset', data = dataset_info, ax=ax2)\n",
    "        plt.title('Percentage of anomaly edges in training dataset')\n",
    "        plt.ylabel('Anomaly share')\n",
    "        ax2.get_legend().remove();\n",
    "    \n",
    "    #The anomaly % plot for test data:\n",
    "    if show_test:\n",
    "        ax3 = plt.subplot(313)\n",
    "        sns.pointplot(x = 'Split (train:test)', y = 'Test_anomaly_percentage', \n",
    "                      hue = 'Dataset', data = dataset_info, ax=ax3)\n",
    "        plt.title('Percentage of anomaly edges in test dataset')\n",
    "        plt.ylabel('Anomaly share')\n",
    "        ax3.get_legend().remove();\n",
    "    \n",
    "    #plt.savefig(\"Figures/auc_and_anomaly_percentage_\" + df_name + \".png\")\n",
    "    plt.show();\n",
    "    \n",
    "    \n",
    "#single_dataset_plot(\"DARPA\", show_train=True, show_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd469014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_per_method(dataset: str):\n",
    "    '''\n",
    "    dataset: one of DATASETS\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv('./CSV/rav_change_s.csv')\n",
    "    df['Size'] = df['Size'].astype(str)\n",
    "    df['Time'] = df['Time'].apply(lambda x: log2(x))\n",
    "    df['Method_full'] = df['Method'] + \" + \" + df['MIDAS']\n",
    "    \n",
    "    plt.figure(figsize=(8,2), dpi=100)\n",
    "    sns.scatterplot(x = 'Size', y = 'Time', data = df[df['Dataset']==dataset], hue='Method_full')\n",
    "    plt.legend(title='')\n",
    "    plt.title('Running time of different sample sizes in dataset ' + dataset)\n",
    "    plt.xlabel(\"Maximum size of the training graph (# unique edges)\")\n",
    "    plt.ylabel(\"log_2(Time) (in seconds)\")\n",
    "    \n",
    "    if dataset + '.png' not in os.listdir('./Figures/Time_vs_sample_size/'):\n",
    "        plt.savefig('./Figures/Time_vs_sample_size/' + dataset + '.png', bbox_inches='tight')\n",
    "    \n",
    "    plt.legend(bbox_to_anchor=(1,1))\n",
    "    plt.show();\n",
    "    \n",
    "# for dataset in DATASETS:\n",
    "#     plot_time_per_method(df, dataset)\n",
    "\n",
    "plot_time_per_method(df, 'NYC_Taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c294fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_test(X_test, y_test, G: nx.Graph) -> tuple:\n",
    "    '''\n",
    "    Filter out edges already present in G\n",
    "    Filter out using a vertex never seen before in G\n",
    "    '''\n",
    "    \n",
    "    good_rows = [(edge[0], edge[1], label) for (edge, label) in zip(X_test, y_test) if \\\n",
    "                 ((edge[0], edge[1]) not in G.edges) and (edge[0] in G and edge[1] in G)]\n",
    "    \n",
    "    print(\"Filtered out\", len(y_test) - len(good_rows), \"rows.\")\n",
    "    print(\"Filtered out\", round((len(y_test) - len(good_rows))/len(y_test)*100, 3), \"% of the original dataset.\")\n",
    "    \n",
    "    return [(edge[0], edge[1]) for edge in good_rows], [edge[2] for edge in good_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abae9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New hash, just for testing:\n",
    "def bytes_to_long(bytes):\n",
    "    assert len(bytes) == 8\n",
    "    return sum((b << (k * 8) for k, b in enumerate(bytes)))\n",
    "\n",
    "\n",
    "def murmur64(data, seed = 19820125):\n",
    "\n",
    "    m = 0xc6a4a7935bd1e995\n",
    "    r = 47\n",
    "\n",
    "    MASK = 2 ** 64 - 1\n",
    "\n",
    "    data_as_bytes = bytearray(data)\n",
    "\n",
    "    h = seed ^ ((m * len(data_as_bytes)) & MASK)\n",
    "\n",
    "    off = int(len(data_as_bytes)/8)*8\n",
    "    for ll in range(0, off, 8):\n",
    "        k = bytes_to_long(data_as_bytes[ll:ll + 8])\n",
    "        k = (k * m) & MASK\n",
    "        k = k ^ ((k >> r) & MASK)\n",
    "        k = (k * m) & MASK\n",
    "        h = (h ^ k)\n",
    "        h = (h * m) & MASK\n",
    "\n",
    "    l = len(data_as_bytes) & 7\n",
    "\n",
    "    if l >= 7:\n",
    "        h = (h ^ (data_as_bytes[off+6] << 48))\n",
    "\n",
    "    if l >= 6:\n",
    "        h = (h ^ (data_as_bytes[off+5] << 40))\n",
    "\n",
    "    if l >= 5:\n",
    "        h = (h ^ (data_as_bytes[off+4] << 32))\n",
    "\n",
    "    if l >= 4:\n",
    "        h = (h ^ (data_as_bytes[off+3] << 24))\n",
    "\n",
    "    if l >= 3:\n",
    "        h = (h ^ (data_as_bytes[off+2] << 16))\n",
    "\n",
    "    if l >= 2:\n",
    "        h = (h ^ (data_as_bytes[off+1] << 8))\n",
    "\n",
    "    if l >= 1:\n",
    "        h = (h ^ data_as_bytes[off])\n",
    "        h = (h * m) & MASK\n",
    "\n",
    "    h = h ^ ((h >> r) & MASK)\n",
    "    h = (h * m) & MASK\n",
    "    h = h ^ ((h >> r) & MASK)\n",
    "\n",
    "    return h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
